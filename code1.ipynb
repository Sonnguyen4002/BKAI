{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:22.757747Z",
     "start_time": "2024-11-22T15:12:09.842710Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n",
    "from collections import OrderedDict\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:22.773173Z",
     "start_time": "2024-11-22T15:12:22.757747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ],
   "id": "e0a9ac82222659d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:38.169030Z",
     "start_time": "2024-11-22T15:12:30.814902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ],
   "id": "ddd1070fd2c7ef4e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:41.970572Z",
     "start_time": "2024-11-22T15:12:38.169030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# In thông tin chi tiết mô hình\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, 3, 256, 256),  # Batch size = 1, RGB image, size 256x256\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
    "    depth=3  # Hiển thị sâu đến cấp 3\n",
    ")\n"
   ],
   "id": "2a8711c266d6ccd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "==========================================================================================================================================================================\n",
       "UnetPlusPlus                                  [1, 3, 256, 256]          [1, 3, 256, 256]          --                        --                        --\n",
       "├─ResNetEncoder: 1-1                          [1, 3, 256, 256]          [1, 3, 256, 256]          --                        --                        --\n",
       "│    └─Conv2d: 2-1                            [1, 3, 256, 256]          [1, 64, 128, 128]         9,408                     [7, 7]                    154,140,672\n",
       "│    └─BatchNorm2d: 2-2                       [1, 64, 128, 128]         [1, 64, 128, 128]         128                       --                        128\n",
       "│    └─ReLU: 2-3                              [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --                        --\n",
       "│    └─MaxPool2d: 2-4                         [1, 64, 128, 128]         [1, 64, 64, 64]           --                        3                         --\n",
       "│    └─Sequential: 2-5                        [1, 64, 64, 64]           [1, 64, 64, 64]           --                        --                        --\n",
       "│    │    └─BasicBlock: 3-1                   [1, 64, 64, 64]           [1, 64, 64, 64]           73,984                    --                        301,990,144\n",
       "│    │    └─BasicBlock: 3-2                   [1, 64, 64, 64]           [1, 64, 64, 64]           73,984                    --                        301,990,144\n",
       "│    │    └─BasicBlock: 3-3                   [1, 64, 64, 64]           [1, 64, 64, 64]           73,984                    --                        301,990,144\n",
       "│    └─Sequential: 2-6                        [1, 64, 64, 64]           [1, 128, 32, 32]          --                        --                        --\n",
       "│    │    └─BasicBlock: 3-4                   [1, 64, 64, 64]           [1, 128, 32, 32]          230,144                   --                        234,881,792\n",
       "│    │    └─BasicBlock: 3-5                   [1, 128, 32, 32]          [1, 128, 32, 32]          295,424                   --                        301,990,400\n",
       "│    │    └─BasicBlock: 3-6                   [1, 128, 32, 32]          [1, 128, 32, 32]          295,424                   --                        301,990,400\n",
       "│    │    └─BasicBlock: 3-7                   [1, 128, 32, 32]          [1, 128, 32, 32]          295,424                   --                        301,990,400\n",
       "│    └─Sequential: 2-7                        [1, 128, 32, 32]          [1, 256, 16, 16]          --                        --                        --\n",
       "│    │    └─BasicBlock: 3-8                   [1, 128, 32, 32]          [1, 256, 16, 16]          919,040                   --                        234,882,560\n",
       "│    │    └─BasicBlock: 3-9                   [1, 256, 16, 16]          [1, 256, 16, 16]          1,180,672                 --                        301,990,912\n",
       "│    │    └─BasicBlock: 3-10                  [1, 256, 16, 16]          [1, 256, 16, 16]          1,180,672                 --                        301,990,912\n",
       "│    │    └─BasicBlock: 3-11                  [1, 256, 16, 16]          [1, 256, 16, 16]          1,180,672                 --                        301,990,912\n",
       "│    │    └─BasicBlock: 3-12                  [1, 256, 16, 16]          [1, 256, 16, 16]          1,180,672                 --                        301,990,912\n",
       "│    │    └─BasicBlock: 3-13                  [1, 256, 16, 16]          [1, 256, 16, 16]          1,180,672                 --                        301,990,912\n",
       "│    └─Sequential: 2-8                        [1, 256, 16, 16]          [1, 512, 8, 8]            --                        --                        --\n",
       "│    │    └─BasicBlock: 3-14                  [1, 256, 16, 16]          [1, 512, 8, 8]            3,673,088                 --                        234,884,096\n",
       "│    │    └─BasicBlock: 3-15                  [1, 512, 8, 8]            [1, 512, 8, 8]            4,720,640                 --                        301,991,936\n",
       "│    │    └─BasicBlock: 3-16                  [1, 512, 8, 8]            [1, 512, 8, 8]            4,720,640                 --                        301,991,936\n",
       "├─UnetPlusPlusDecoder: 1-2                    [1, 3, 256, 256]          [1, 16, 256, 256]         --                        --                        --\n",
       "│    └─ModuleDict: 2-9                        --                        --                        --                        --                        --\n",
       "│    │    └─DecoderBlock: 3-17                [1, 512, 8, 8]            [1, 256, 16, 16]          2,360,320                 --                        603,980,800\n",
       "│    │    └─DecoderBlock: 3-18                [1, 256, 16, 16]          [1, 128, 32, 32]          590,336                   --                        603,980,288\n",
       "│    │    └─DecoderBlock: 3-19                [1, 128, 32, 32]          [1, 64, 64, 64]           147,712                   --                        603,980,032\n",
       "│    │    └─DecoderBlock: 3-20                [1, 64, 64, 64]           [1, 64, 128, 128]         110,848                   --                        1,811,939,584\n",
       "│    │    └─DecoderBlock: 3-21                [1, 256, 16, 16]          [1, 128, 32, 32]          737,792                   --                        754,975,232\n",
       "│    │    └─DecoderBlock: 3-22                [1, 128, 32, 32]          [1, 64, 64, 64]           184,576                   --                        754,974,976\n",
       "│    │    └─DecoderBlock: 3-23                [1, 64, 64, 64]           [1, 64, 128, 128]         147,712                   --                        2,415,919,360\n",
       "│    │    └─DecoderBlock: 3-24                [1, 128, 32, 32]          [1, 64, 64, 64]           221,440                   --                        905,969,920\n",
       "│    │    └─DecoderBlock: 3-25                [1, 64, 64, 64]           [1, 64, 128, 128]         184,576                   --                        3,019,899,136\n",
       "│    │    └─DecoderBlock: 3-26                [1, 64, 64, 64]           [1, 32, 128, 128]         101,504                   --                        1,660,944,512\n",
       "│    │    └─DecoderBlock: 3-27                [1, 32, 128, 128]         [1, 16, 256, 256]         6,976                     --                        452,984,896\n",
       "├─SegmentationHead: 1-3                       [1, 16, 256, 256]         [1, 3, 256, 256]          --                        --                        --\n",
       "│    └─Conv2d: 2-10                           [1, 16, 256, 256]         [1, 3, 256, 256]          435                       [3, 3]                    28,508,160\n",
       "│    └─Identity: 2-11                         [1, 3, 256, 256]          [1, 3, 256, 256]          --                        --                        --\n",
       "│    └─Activation: 2-12                       [1, 3, 256, 256]          [1, 3, 256, 256]          --                        --                        --\n",
       "│    │    └─Identity: 3-28                    [1, 3, 256, 256]          [1, 3, 256, 256]          --                        --                        --\n",
       "==========================================================================================================================================================================\n",
       "Total params: 26,078,899\n",
       "Trainable params: 26,078,899\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 18.40\n",
       "==========================================================================================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 266.34\n",
       "Params size (MB): 104.32\n",
       "Estimated Total Size (MB): 371.44\n",
       "=========================================================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:42.111606Z",
     "start_time": "2024-11-22T15:12:41.970572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = 3\n",
    "learning_rate = 1e-04\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "image = \"data/train/train/\"\n",
    "masks =  \"data/train_gt/train_gt/\"\n",
    "\n",
    "train_size = 0.9\n",
    "valid_size = 0.1\n",
    "torch.manual_seed(1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "49368632b075f12b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32f7ec8beeeda5b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:36:52.605971Z",
     "start_time": "2024-11-22T15:36:52.584777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class UNetDataClass(Dataset):\n",
    "    def __init__(self, images_path, masks_path=None):\n",
    "        super(UNetDataClass, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        images_list = [os.path.join(images_path, image_name) for image_name in images_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.masks_path = masks_path\n",
    "        self.masks_list = None\n",
    "        \n",
    "        if masks_path:\n",
    "            masks_list = os.listdir(masks_path)\n",
    "            masks_list = [os.path.join(masks_path, mask_name) for mask_name in masks_list]\n",
    "            self.masks_list = masks_list\n",
    "        \n",
    "        self.transform = Compose([Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n",
    "                     PILToTensor()])\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        \n",
    "        # Open image\n",
    "        data = Image.open(img_path).convert(\"RGB\")\n",
    "        data = self.transform(data) / 255\n",
    "        \n",
    "        if self.masks_list:  # If masks are available\n",
    "            mask_path = self.masks_list[index]\n",
    "            label = Image.open(mask_path).convert(\"L\")\n",
    "            label = self.transform(label) / 255\n",
    "            label = torch.where(label > 0.65, 1.0, 0.0)\n",
    "            label = torch.argmax(label, 0).type(torch.int64)\n",
    "            \n",
    "            return data, label\n",
    "        \n",
    "        return data, img_path  # For test set, return data and path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ],
   "id": "f2de20ddbc85860b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:37:25.804711Z",
     "start_time": "2024-11-22T15:37:25.744883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = 'data/test/test'\n",
    "unet_dataset = UNetDataClass(image, masks)\n",
    "unet_test = UNetDataClass(test, None)\n",
    "test_dataloader = DataLoader(unet_test, batch_size=batch_size, shuffle=True)"
   ],
   "id": "ba6f5d9acf8c5c71",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:42.237015Z",
     "start_time": "2024-11-22T15:12:42.205781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set, valid_set = random_split(unet_dataset, \n",
    "                                    [int(train_size * len(unet_dataset)) , \n",
    "                                     int(valid_size * len(unet_dataset))])\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ],
   "id": "dcd861ee54fa29fd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:12:42.268667Z",
     "start_time": "2024-11-22T15:12:42.237015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, epochs=5):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels)  \n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "\n",
    "\n",
    "        # Validation \n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "     \n",
    " \n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"    Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"    Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return "
   ],
   "id": "bc909bf2f5fec469",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:28:01.700559Z",
     "start_time": "2024-11-22T15:12:42.268667Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_validate(model,train_dataloader,valid_dataloader, optimizer,criterion)",
   "id": "4d5b6a9d17e4977b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]\n",
      "    Train Loss: 0.4220\n",
      "    Val Loss: 0.1277\n",
      "Epoch [2/5]\n",
      "    Train Loss: 0.0961\n",
      "    Val Loss: 0.0904\n",
      "Epoch [3/5]\n",
      "    Train Loss: 0.0656\n",
      "    Val Loss: 0.0653\n",
      "Epoch [4/5]\n",
      "    Train Loss: 0.0493\n",
      "    Val Loss: 0.0547\n",
      "Epoch [5/5]\n",
      "    Train Loss: 0.0373\n",
      "    Val Loss: 0.0495\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T17:18:53.427929Z",
     "start_time": "2024-11-22T17:18:53.381053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rle_encoding(mask):\n",
    "    \"\"\"\n",
    "    Convert a binary mask into RLE format.\n",
    "    Args:\n",
    "        mask (np.ndarray): 2D numpy array of 0s and 1s representing the binary mask.\n",
    "    Returns:\n",
    "        str: Run-Length Encoding as a string.\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten(order='F')  # Flatten in column-major order\n",
    "    pixels = np.concatenate([[0], pixels, [0]])  # Add boundary pixels\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(map(str, runs))\n",
    "\n",
    "def evaluate(model, test_loader, output_csv=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test_loader and create a submission file with RLE encoding.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        test_loader: DataLoader for the test set.\n",
    "        output_csv: Path to save the submission CSV.\n",
    "    \"\"\"\n",
    "    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n",
    "    submission_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, image_paths in test_loader:\n",
    "            images = images.to(device)  # Đưa ảnh về thiết bị\n",
    "            outputs = model(images)  # Dự đoán\n",
    "\n",
    "            # Duyệt qua từng ảnh trong batch\n",
    "            for i, image_path in enumerate(image_paths):\n",
    "                predictions = torch.argmax(outputs[i], dim=0)  # Dự đoán cho ảnh i\n",
    "                predicted_image = predictions.cpu().numpy()  # Chuyển dự đoán thành NumPy array\n",
    "\n",
    "                # Mã hóa RLE cho mỗi lớp (0, 1, 2)\n",
    "                rle_mask = rle_encoding(predicted_image)\n",
    "\n",
    "                # Lấy tên file không có phần mở rộng\n",
    "                file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "                # Thêm kết quả vào danh sách\n",
    "                submission_data.append({\n",
    "                    \"Id\": file_name,\n",
    "                    \"Expected\": rle_mask  # Lưu kết quả mã hóa RLE\n",
    "                })\n",
    "\n",
    "    # Tạo DataFrame từ danh sách kết quả\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "\n",
    "    # Lưu thành file CSV\n",
    "    submission_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Submission file saved as {output_csv}\")"
   ],
   "id": "b40ea76f6effd3dd",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T17:18:55.539145Z",
     "start_time": "2024-11-22T17:18:54.463049Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(model, test_dataloader)",
   "id": "9e5f92cd62a63647",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (28,) (29,) (28,) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[79], line 38\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, test_loader, output_csv)\u001B[0m\n\u001B[0;32m     35\u001B[0m predicted_image \u001B[38;5;241m=\u001B[39m predictions\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()  \u001B[38;5;66;03m# Chuyển dự đoán thành NumPy array\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Mã hóa RLE cho mỗi lớp (0, 1, 2)\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m rle_mask \u001B[38;5;241m=\u001B[39m \u001B[43mrle_encoding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_image\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Lấy tên file không có phần mở rộng\u001B[39;00m\n\u001B[0;32m     41\u001B[0m file_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(image_path))[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[1;32mIn[79], line 12\u001B[0m, in \u001B[0;36mrle_encoding\u001B[1;34m(mask)\u001B[0m\n\u001B[0;32m     10\u001B[0m pixels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([[\u001B[38;5;241m0\u001B[39m], pixels, [\u001B[38;5;241m0\u001B[39m]])  \u001B[38;5;66;03m# Add boundary pixels\u001B[39;00m\n\u001B[0;32m     11\u001B[0m runs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(pixels[\u001B[38;5;241m1\u001B[39m:] \u001B[38;5;241m!=\u001B[39m pixels[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 12\u001B[0m runs[\u001B[38;5;241m1\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m runs[::\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mstr\u001B[39m, runs))\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (28,) (29,) (28,) "
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:32:11.245941Z",
     "start_time": "2024-11-22T16:32:10.163451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lấy một batch từ train_dataloader\n",
    "for i, (batch_images, batch_labels) in enumerate(train_dataloader):\n",
    "    # Kiểm tra nếu batch có ít nhất một nhãn bằng 0\n",
    "    if (batch_labels == 1).any():\n",
    "        print(f\"Batch index: {i}\")\n",
    "        break\n",
    "\n",
    "# Đưa ảnh về thiết bị (CPU/GPU)\n",
    "images = batch_images.to(device)\n",
    "labels = batch_labels.to(device)  # Nếu cần nhãn\n",
    "\n",
    "# Chạy ảnh qua mô hình\n",
    "model.eval()  # Chuyển sang chế độ đánh giá\n",
    "with torch.no_grad():  # Không cần tính toán gradient\n",
    "    outputs = model(images)  # Dự đoán\n",
    "\n",
    "# Lấy nhãn của ảnh đầu tiên trong batch\n",
    "label_image = labels[1]  # Nhãn của ảnh thứ hai trong batch (H, W)\n",
    "\n",
    "# Đếm số lượng pixel với giá trị 1 và 2\n",
    "num_ones = torch.sum(label_image == 1).item()\n",
    "num_twos = torch.sum(label_image == 2).item()\n",
    "print(f\"Number of pixels with value 1: {num_ones}\")\n",
    "print(f\"Number of pixels with value 2: {num_twos}\")\n",
    "\n",
    "# Kiểm tra phân phối các giá trị trong nhãn\n",
    "values, counts = torch.unique(label_image, return_counts=True)\n",
    "print(\"Distribution of pixel values:\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Value: {value.item()}, Count: {count.item()}\")\n",
    "\n",
    "# Chuyển nhãn sang NumPy để hiển thị bằng matplotlib\n",
    "label_image_np = label_image.cpu().numpy()\n",
    "\n",
    "# Hiển thị nhãn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(label_image_np, cmap=\"viridis\")  # Sử dụng cmap phù hợp\n",
    "plt.title(\"Label Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ],
   "id": "8aa0e5d00cdd1547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index: 2\n",
      "Number of pixels with value 1: 0\n",
      "Number of pixels with value 2: 64151\n",
      "Distribution of pixel values:\n",
      "Value: 0, Count: 1385\n",
      "Value: 2, Count: 64151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:44:07.665526Z",
     "start_time": "2024-11-22T15:44:07.634274Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "466b6fe9aebda163",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T17:00:48.691476Z",
     "start_time": "2024-11-22T17:00:43.971523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chuyển mô hình sang chế độ đánh giá\n",
    "image, path = next(iter(test_dataloader))\n",
    "images = image.to(device)\n",
    "model.eval()\n",
    "print(path)\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)  # Chạy mô hình trên batch\n",
    "    predictions = torch.argmax(outputs, dim=1)  # Lấy nhãn có xác suất cao nhất\n",
    "\n",
    "# Chọn nhãn dự đoán của ảnh đầu tiên trong batch\n",
    "predicted_image = predictions[0]  # (H, W)\n",
    "\n",
    "# Kiểm tra phân phối các giá trị trong nhãn dự đoán\n",
    "values, counts = torch.unique(predicted_image, return_counts=True)\n",
    "print(\"Distribution of predicted pixel values:\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Value: {value.item()}, Count: {count.item()}\")\n",
    "\n",
    "# Hiển thị dự đoán\n",
    "predicted_image_np = predicted_image.cpu().numpy()  # Chuyển sang NumPy để hiển thị\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(predicted_image_np, cmap=\"viridis\")  # Dùng cmap để phân biệt các lớp\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ],
   "id": "a5ceaa7767ebb1a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/test/test\\\\aafac813fe3ccba3e032dd2948a80c64.jpeg', 'data/test/test\\\\8395e56a6d9ba9d45c3dbc695325ded4.jpeg')\n",
      "Distribution of predicted pixel values:\n",
      "Value: 0, Count: 583\n",
      "Value: 1, Count: 44\n",
      "Value: 2, Count: 64909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T17:02:08.884746Z",
     "start_time": "2024-11-22T17:02:08.869108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "path = 'data/test/test\\\\aafac813fe3ccba3e032dd2948a80c64.jpeg'\n",
    "\n",
    "# Lấy tên file không bao gồm phần mở rộng\n",
    "file_name = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "print(file_name)  # Kết quả: aafac813fe3ccba3e032dd2948a80c64\n"
   ],
   "id": "1f99f49471780a9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aafac813fe3ccba3e032dd2948a80c64\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18b5a4e641f00245"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
