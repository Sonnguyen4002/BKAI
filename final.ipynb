{
 "cells": [
  {
   "cell_type": "code",
   "id": "c4c175dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:00.506159Z",
     "iopub.status.busy": "2023-11-17T04:33:00.505846Z",
     "iopub.status.idle": "2023-11-17T04:33:10.774850Z",
     "shell.execute_reply": "2023-11-17T04:33:10.773918Z"
    },
    "papermill": {
     "duration": 10.284104,
     "end_time": "2023-11-17T04:33:10.777335",
     "exception": false,
     "start_time": "2023-11-17T04:33:00.493231",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:02:58.648749Z",
     "start_time": "2024-11-23T15:02:58.633097Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "98d8f2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:11.978524Z",
     "iopub.status.busy": "2023-11-17T04:33:11.978236Z",
     "iopub.status.idle": "2023-11-17T04:33:11.990393Z",
     "shell.execute_reply": "2023-11-17T04:33:11.989641Z"
    },
    "papermill": {
     "duration": 0.027012,
     "end_time": "2023-11-17T04:33:11.992493",
     "exception": false,
     "start_time": "2023-11-17T04:33:11.965481",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:03:03.607451Z",
     "start_time": "2024-11-23T15:03:03.576223Z"
    }
   },
   "source": [
    "class DatasetCustom(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b00b975c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.017102Z",
     "iopub.status.busy": "2023-11-17T04:33:12.016817Z",
     "iopub.status.idle": "2023-11-17T04:33:12.308287Z",
     "shell.execute_reply": "2023-11-17T04:33:12.307353Z"
    },
    "papermill": {
     "duration": 0.306037,
     "end_time": "2023-11-17T04:33:12.310186",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.004149",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:03:09.020629Z",
     "start_time": "2024-11-23T15:03:08.958090Z"
    }
   },
   "source": [
    "images_path = \"data/train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = 'data/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e927f980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.334549Z",
     "iopub.status.busy": "2023-11-17T04:33:12.334265Z",
     "iopub.status.idle": "2023-11-17T04:33:12.655721Z",
     "shell.execute_reply": "2023-11-17T04:33:12.654588Z"
    },
    "papermill": {
     "duration": 0.336065,
     "end_time": "2023-11-17T04:33:12.657918",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.321853",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:03:13.507413Z",
     "start_time": "2024-11-23T15:03:13.434249Z"
    }
   },
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = 'data/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "95d03341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.684107Z",
     "iopub.status.busy": "2023-11-17T04:33:12.683415Z",
     "iopub.status.idle": "2023-11-17T04:33:12.688730Z",
     "shell.execute_reply": "2023-11-17T04:33:12.687853Z"
    },
    "papermill": {
     "duration": 0.02092,
     "end_time": "2023-11-17T04:33:12.690872",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.669952",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:03:18.000626Z",
     "start_time": "2024-11-23T15:03:17.985025Z"
    }
   },
   "source": [
    "dataset = DatasetCustom(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (256,256),\n",
    "                             transform = None)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ],
   "id": "30b2b07caa2eda32"
  },
  {
   "cell_type": "code",
   "id": "395917c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.715773Z",
     "iopub.status.busy": "2023-11-17T04:33:12.715480Z",
     "iopub.status.idle": "2023-11-17T04:33:55.513504Z",
     "shell.execute_reply": "2023-11-17T04:33:55.512413Z"
    },
    "papermill": {
     "duration": 42.813372,
     "end_time": "2023-11-17T04:33:55.516034",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.702662",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:04:22.001318Z",
     "start_time": "2024-11-23T15:03:22.719216Z"
    }
   },
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "best = 10000\n",
    "origin_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "282af1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.728401Z",
     "iopub.status.busy": "2023-11-17T04:33:56.728085Z",
     "iopub.status.idle": "2023-11-17T04:33:56.735884Z",
     "shell.execute_reply": "2023-11-17T04:33:56.734882Z"
    },
    "papermill": {
     "duration": 0.024157,
     "end_time": "2023-11-17T04:33:56.738018",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.713861",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:05:12.989361Z",
     "start_time": "2024-11-23T15:05:12.974352Z"
    }
   },
   "source": [
    "class UNetDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        assert image.shape[:2] == label.shape[:2]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "689cfb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.764418Z",
     "iopub.status.busy": "2023-11-17T04:33:56.763924Z",
     "iopub.status.idle": "2023-11-17T04:33:56.771880Z",
     "shell.execute_reply": "2023-11-17T04:33:56.770794Z"
    },
    "papermill": {
     "duration": 0.023247,
     "end_time": "2023-11-17T04:33:56.773829",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.750582",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:20:05.216187Z",
     "start_time": "2024-11-23T15:20:05.092049Z"
    }
   },
   "source": [
    "transformation = A.Compose([\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "27432c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.802769Z",
     "iopub.status.busy": "2023-11-17T04:33:56.802418Z",
     "iopub.status.idle": "2023-11-17T04:33:56.809969Z",
     "shell.execute_reply": "2023-11-17T04:33:56.808843Z"
    },
    "papermill": {
     "duration": 0.025438,
     "end_time": "2023-11-17T04:33:56.812628",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.787190",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:05:28.587436Z",
     "start_time": "2024-11-23T15:05:28.556234Z"
    }
   },
   "source": [
    "train_size = 0.9\n",
    "val_size = 0.1\n",
    "torch.manual_seed(123)\n",
    "train_set, valid_set = random_split(UNetDataset(images_data, labels_data, transformation),\n",
    "                                    [int(train_size * len(images_data)) , \n",
    "                                     int(val_size * len(images_data))])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "200bc628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.873729Z",
     "iopub.status.busy": "2023-11-17T04:33:56.873445Z",
     "iopub.status.idle": "2023-11-17T04:33:56.879243Z",
     "shell.execute_reply": "2023-11-17T04:33:56.878266Z"
    },
    "papermill": {
     "duration": 0.021032,
     "end_time": "2023-11-17T04:33:56.881370",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.860338",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:05:42.450903Z",
     "start_time": "2024-11-23T15:05:42.435311Z"
    }
   },
   "source": [
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:05:49.131601Z",
     "start_time": "2024-11-23T15:05:49.115448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "a15b9c8ebab86aa5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "fb96a2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:34:41.288532Z",
     "iopub.status.busy": "2023-11-17T04:34:41.288090Z",
     "iopub.status.idle": "2023-11-17T06:30:57.923850Z",
     "shell.execute_reply": "2023-11-17T06:30:57.922709Z"
    },
    "papermill": {
     "duration": 6976.659187,
     "end_time": "2023-11-17T06:30:57.926139",
     "exception": false,
     "start_time": "2023-11-17T04:34:41.266952",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T06:54:03.567330Z",
     "start_time": "2024-11-23T05:45:47.442153Z"
    }
   },
   "source": [
    "model.to(device)\n",
    "\n",
    "epoch_bar = tqdm(total=origin_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(origin_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += criterion(outputs.float(),labels.long()).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{origin_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best:\n",
    "        best = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        \n",
    "    epoch_bar.update(1)\n",
    "    \n",
    "epoch_bar.close()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.4592715752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   2%|▏         | 1/50 [01:36<1:18:37, 96.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 0.2392044294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   4%|▍         | 2/50 [02:48<1:05:46, 82.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 0.1500769261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   6%|▌         | 3/50 [04:00<1:00:46, 77.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 0.1161187190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   8%|▊         | 4/50 [05:17<59:15, 77.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.0948189777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 5/50 [06:37<58:34, 78.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 0.0782490022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  12%|█▏        | 6/50 [07:57<57:56, 79.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 0.0712339446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  14%|█▍        | 7/50 [09:20<57:31, 80.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 0.0646783194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  16%|█▌        | 8/50 [10:45<57:06, 81.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 0.0597096242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  18%|█▊        | 9/50 [12:11<56:44, 83.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.0563038148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 10/50 [13:39<56:19, 84.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 0.0553003232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  22%|██▏       | 11/50 [15:07<55:40, 85.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 0.0506255277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  24%|██▍       | 12/50 [16:39<55:23, 87.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 0.0482185133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  28%|██▊       | 14/50 [19:49<54:53, 91.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 0.0516066007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 15/50 [21:25<54:15, 93.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.0504061826\n",
      "Epoch [16/50], Loss: 0.0445257197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  32%|███▏      | 16/50 [23:02<53:20, 94.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 0.0421533433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  36%|███▌      | 18/50 [26:09<49:58, 93.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 0.0573275349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  38%|███▊      | 19/50 [27:39<47:46, 92.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 0.0443570123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 20/50 [29:09<45:58, 91.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.0451665026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  42%|████▏     | 21/50 [30:41<44:19, 91.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 0.0428101729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  44%|████▍     | 22/50 [32:09<42:20, 90.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 0.0458516754\n",
      "Epoch [23/50], Loss: 0.0382578683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  48%|████▊     | 24/50 [35:02<38:19, 88.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 0.0418610124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 25/50 [36:24<36:03, 86.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.0494171143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  52%|█████▏    | 26/50 [37:41<33:31, 83.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 0.0560352839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  54%|█████▍    | 27/50 [39:00<31:31, 82.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 0.0493381560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  56%|█████▌    | 28/50 [40:15<29:26, 80.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 0.0472171302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  58%|█████▊    | 29/50 [41:31<27:38, 78.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 0.0462878146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 30/50 [42:47<26:01, 78.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 0.0498634457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  62%|██████▏   | 31/50 [44:05<24:42, 78.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 0.0430582928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  64%|██████▍   | 32/50 [45:21<23:09, 77.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 0.0446898982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  66%|██████▌   | 33/50 [46:36<21:43, 76.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 0.0414499033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  68%|██████▊   | 34/50 [47:52<20:21, 76.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 0.0497866977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 35/50 [49:07<19:00, 76.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 0.0443241079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  72%|███████▏  | 36/50 [50:24<17:48, 76.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 0.0419405570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  74%|███████▍  | 37/50 [51:40<16:31, 76.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 0.0483090650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  76%|███████▌  | 38/50 [52:57<15:17, 76.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 0.0514629205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  78%|███████▊  | 39/50 [54:15<14:04, 76.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 0.0512975245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 40/50 [55:30<12:43, 76.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 0.0494099645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  82%|████████▏ | 41/50 [56:46<11:26, 76.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 0.0636770648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  84%|████████▍ | 42/50 [58:03<10:13, 76.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 0.0432557013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  86%|████████▌ | 43/50 [59:18<08:52, 76.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 0.0484324574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  88%|████████▊ | 44/50 [1:00:34<07:35, 75.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 0.0445578384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 45/50 [1:01:51<06:21, 76.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 0.0510036216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  92%|█████████▏| 46/50 [1:03:07<05:04, 76.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 0.0497159549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  94%|█████████▍| 47/50 [1:04:25<03:50, 76.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 0.0506285137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  96%|█████████▌| 48/50 [1:05:43<02:34, 77.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 0.0508034969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  98%|█████████▊| 49/50 [1:06:57<01:16, 76.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 0.0514693623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 50/50 [1:08:14<00:00, 81.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0473644343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T15:20:05.057090Z",
     "start_time": "2024-11-23T15:05:55.687542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10  \n",
    "save_path = 'model.pth'\n",
    "checkpoint = torch.load(save_path)\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best = checkpoint['loss']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs.float(), labels.long()).item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{start_epoch + num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "\n",
    "\n",
    "    if val_loss < best:\n",
    "        best = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, save_path)\n",
    "\n",
    "    epoch_bar.update(1)\n",
    "    \n",
    "epoch_bar.close()\n"
   ],
   "id": "17e42bb1bfcb3e97",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 1/10 [01:16<11:31, 76.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/33], Loss: 0.0399129758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 2/10 [02:37<10:34, 79.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/33], Loss: 0.0449616373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 3/10 [04:01<09:28, 81.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/33], Loss: 0.0414595246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 4/10 [05:28<08:21, 83.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/33], Loss: 0.0567092542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 5/10 [07:02<07:16, 87.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/33], Loss: 0.0493015320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 6/10 [08:26<05:44, 86.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/33], Loss: 0.0438387295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 7/10 [09:51<04:17, 85.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/33], Loss: 0.0462656843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 8/10 [11:18<02:52, 86.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/33], Loss: 0.0428382906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 9/10 [12:41<01:25, 85.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/33], Loss: 0.0417774905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 10/10 [14:07<00:00, 84.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/33], Loss: 0.0387759328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "a7d38e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:30:58.032350Z",
     "iopub.status.busy": "2023-11-17T06:30:58.032038Z",
     "iopub.status.idle": "2023-11-17T06:31:00.872244Z",
     "shell.execute_reply": "2023-11-17T06:31:00.871278Z"
    },
    "papermill": {
     "duration": 2.894935,
     "end_time": "2023-11-17T06:31:00.874256",
     "exception": false,
     "start_time": "2023-11-17T06:30:57.979321",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:21:29.201219Z",
     "start_time": "2024-11-23T15:21:28.150406Z"
    }
   },
   "source": [
    "checkpoint = torch.load('model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "b7d379c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:02.172392Z",
     "iopub.status.busy": "2023-11-17T06:31:02.171534Z",
     "iopub.status.idle": "2023-11-17T06:31:28.541107Z",
     "shell.execute_reply": "2023-11-17T06:31:28.540319Z"
    },
    "papermill": {
     "duration": 26.427994,
     "end_time": "2023-11-17T06:31:28.543403",
     "exception": false,
     "start_time": "2023-11-17T06:31:02.115409",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:22:10.032871Z",
     "start_time": "2024-11-23T15:21:34.349614Z"
    }
   },
   "source": [
    "model.eval()\n",
    "for i in os.listdir(\"data/test/test\"):\n",
    "    img_path = os.path.join(\"data/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (256, 256))\n",
    "    transformed = val_transformation(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) "
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "a341dddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:28.652348Z",
     "iopub.status.busy": "2023-11-17T06:31:28.651596Z",
     "iopub.status.idle": "2023-11-17T06:31:31.862445Z",
     "shell.execute_reply": "2023-11-17T06:31:31.861295Z"
    },
    "papermill": {
     "duration": 3.267238,
     "end_time": "2023-11-17T06:31:31.864765",
     "exception": false,
     "start_time": "2023-11-17T06:31:28.597527",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-23T15:23:28.022274Z",
     "start_time": "2024-11-23T15:23:23.254229Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = 'BKAI-IGH/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'submission2.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\\019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "prediction\\02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "prediction\\0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "prediction\\05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "prediction\\05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "prediction\\0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "prediction\\0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "prediction\\0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "prediction\\0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
      "prediction\\0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "prediction\\0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "prediction\\1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "prediction\\1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "prediction\\13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "prediction\\1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "prediction\\15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "prediction\\1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "prediction\\1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "prediction\\1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "prediction\\1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "prediction\\26679bff55177a34fc01019eec999fd8.jpeg\n",
      "prediction\\268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "prediction\\27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "prediction\\285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "prediction\\2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "prediction\\2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "prediction\\2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "prediction\\2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "prediction\\30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "prediction\\314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "prediction\\318ecf467d7ad048df39beb176363408.jpeg\n",
      "prediction\\3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "prediction\\343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
      "prediction\\3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "prediction\\391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "prediction\\395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "prediction\\39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "prediction\\39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "prediction\\3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "prediction\\3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "prediction\\3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "prediction\\3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "prediction\\3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "prediction\\3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "prediction\\3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "prediction\\41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "prediction\\425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "prediction\\4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "prediction\\45b21960c94b0aab4c024a573c692195.jpeg\n",
      "prediction\\461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "prediction\\4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "prediction\\4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "prediction\\4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "prediction\\4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "prediction\\4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "prediction\\4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "prediction\\4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "prediction\\4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "prediction\\5026b3550534bca540e24f489284b8e6.jpeg\n",
      "prediction\\50534bca540e24f489284b8e6953ad88.jpeg\n",
      "prediction\\54ba59c7de13a35276a476420655433a.jpeg\n",
      "prediction\\559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "prediction\\5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "prediction\\5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "prediction\\5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "prediction\\5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "prediction\\5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "prediction\\5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "prediction\\60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "prediction\\60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "prediction\\6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "prediction\\6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "prediction\\625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "prediction\\626650908b1cb932a767bf5487ced51b.jpeg\n",
      "prediction\\633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "prediction\\63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "prediction\\6679bff55177a34fc01019eec999fd84.jpeg\n",
      "prediction\\66e057db382b8564872a27301a654864.jpeg\n",
      "prediction\\677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "prediction\\67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "prediction\\68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "prediction\\692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "prediction\\6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "prediction\\6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
      "prediction\\6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "prediction\\6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "prediction\\6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "prediction\\6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "prediction\\710d568df17586ad8f3297c819c90895.jpeg\n",
      "prediction\\71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "prediction\\72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "prediction\\7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "prediction\\77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "prediction\\780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "prediction\\782707d7c359e27888daefee82519763.jpeg\n",
      "prediction\\7936140a2d5fc1443c4e445927738677.jpeg\n",
      "prediction\\7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "prediction\\7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "prediction\\7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "prediction\\7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "prediction\\7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "prediction\\7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "prediction\\7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "prediction\\7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "prediction\\80c643782707d7c359e27888daefee82.jpeg\n",
      "prediction\\80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "prediction\\82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "prediction\\8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "prediction\\85a04faeeb2b535797395305af926a6f.jpeg\n",
      "prediction\\87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "prediction\\88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "prediction\\8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "prediction\\8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "prediction\\8cbdf366e057db382b8564872a27301a.jpeg\n",
      "prediction\\8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "prediction\\8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "prediction\\936de314f2d95e6c487ffa651b477422.jpeg\n",
      "prediction\\94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "prediction\\9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "prediction\\97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "prediction\\98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "prediction\\998906d3694abb47953b0e4909384b57.jpeg\n",
      "prediction\\9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "prediction\\9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "prediction\\a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "prediction\\a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "prediction\\a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "prediction\\a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "prediction\\a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "prediction\\a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "prediction\\a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "prediction\\a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "prediction\\aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "prediction\\ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "prediction\\aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "prediction\\af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "prediction\\afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "prediction\\b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "prediction\\b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "prediction\\be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "prediction\\be86f03d900fd197cd955fa095f97845.jpeg\n",
      "prediction\\bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "prediction\\c193ac8d551c149b60f2965341caf528.jpeg\n",
      "prediction\\c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "prediction\\c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "prediction\\c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "prediction\\c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "prediction\\c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "prediction\\c695325ded465efde988dfb96d081533.jpeg\n",
      "prediction\\c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "prediction\\ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "prediction\\cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "prediction\\cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "prediction\\cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "prediction\\cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "prediction\\cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "prediction\\cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
      "prediction\\cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "prediction\\d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "prediction\\d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "prediction\\d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "prediction\\d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "prediction\\d694539ef2424a9218697283baa3657e.jpeg\n",
      "prediction\\d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "prediction\\db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "prediction\\dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "prediction\\dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "prediction\\dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "prediction\\dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "prediction\\df366e057db382b8564872a27301a654.jpeg\n",
      "prediction\\df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "prediction\\e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "prediction\\e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "prediction\\e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "prediction\\e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "prediction\\e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "prediction\\e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "prediction\\e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "prediction\\e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "prediction\\e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "prediction\\e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "prediction\\e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "prediction\\e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "prediction\\ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "prediction\\eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "prediction\\eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "prediction\\eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "prediction\\f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "prediction\\f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "prediction\\f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "prediction\\f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "prediction\\f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "prediction\\f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "prediction\\faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "prediction\\fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "prediction\\fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "prediction\\fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "prediction\\fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "prediction\\ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "prediction\\ff55177a34fc01019eec999fd84e679b.jpeg\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "349e3a68794c1c1b"
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 4002781,
     "sourceId": 6983304,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7164.401292,
   "end_time": "2023-11-17T06:31:35.350673",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-17T04:32:10.949381",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
